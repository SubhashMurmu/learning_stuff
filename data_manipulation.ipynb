{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOOD/iJaKPvEDHljY5T72UF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SubhashMurmu/learning_stuff/blob/main/data_manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from matplotlib_inline import backend_inline\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "wORIaNN5Dlxx",
        "outputId": "364c98bc-d6a1-45bb-ffe6-c5fc7ffc4690",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'd2l'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-129-9479b7ad1410>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib_inline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_inline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0md2l\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'd2l'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "Y8OQFXk1q6_4"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(12,dtype=torch.float32)   #to fill in the tensor x\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUYyY5SNrwfr",
        "outputId": "366e30b0-a93e-495b-a389-80ced6d57dfa"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.numel()  #no of elements in the tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP__6HZ0sVar",
        "outputId": "6c44877f-0225-4a77-b26d-9c21c19715ea"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape #to get dimension and size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywFowljJssDC",
        "outputId": "b3cc979a-b9bf-4ffd-a619-1b5c78d49e3b"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = x.reshape(3,4)  #(row , column)\n",
        "X                   #given a tensor of size n and target (h,w), we know that w=n/h.\n",
        "                    # if(soemthing , -1) then -1 denotes the above calculation done by the torch library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAzc15yJsxun",
        "outputId": "7546e32d-d980-4a82-cb26-dc1adfa83233"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros((2,3,4)) #to make all zeroes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmepPwQjtX2S",
        "outputId": "1ef6e055-08f4-4526-c098-e60e5ae27939"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones((2,3,4)) #make all ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSA8RGIxu8Tj",
        "outputId": "3f5723bc-e6c8-492e-ade3-cb96c83a93ce"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(3,4) #random numbers from gaussian distribution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csp5tjeGvC28",
        "outputId": "942a9213-f0e8-41f7-d1ca-729259398f94"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0618,  0.3370,  0.7385, -1.2018],\n",
              "        [ 0.2115, -1.6247,  0.7337,  0.4885],\n",
              "        [-1.4317,  0.3723,  0.9424, -1.5620]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])  #making my own custom tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np3EiR-uvU5B",
        "outputId": "4b28592a-f168-47de-b408-c84484d0b5b0"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4],\n",
              "        [4, 3, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[-1] , X[1:3] #slicing operation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WTBDsb0xXmZ",
        "outputId": "c28b2602-4cda-419a-cf09-f78cd3f3a240"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 8.,  9., 10., 11.]),\n",
              " tensor([[ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1,2] = 17  #indexing\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUcAFEqfzSLf",
        "outputId": "41159b3b-4573-444b-9f15-263506afb0eb"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5., 17.,  7.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[:2 , : ] = 12 #(row slicing, column slicing)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXgKYzbKzprM",
        "outputId": "6666b9bf-4d4c-4abe-b116-1dafc1ae95d0"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12., 12., 12., 12.],\n",
              "        [12., 12., 12., 12.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.exp(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW1hfgc20Gv9",
        "outputId": "b943e924-12f9-458f-bee0-1677f77d46a3"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([162754.7969, 162754.7969, 162754.7969, 162754.7969, 162754.7969,\n",
              "        162754.7969, 162754.7969, 162754.7969,   2980.9580,   8103.0840,\n",
              "         22026.4648,  59874.1406])"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1,2,4,8])\n",
        "y = torch.tensor([2,2,2,2])\n",
        "x+y , x-y , x*y , x/y ,x**y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va5UaEAG2j_l",
        "outputId": "1e44b083-12b5-4483-c4a4-7f14d0011f14"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 3,  4,  6, 10]),\n",
              " tensor([-1,  0,  2,  6]),\n",
              " tensor([ 2,  4,  8, 16]),\n",
              " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
              " tensor([ 1,  4, 16, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.arange(12,dtype=torch.float32).reshape((3,4))    #torch.cat((X, Y), dim=0) → Concatenate along rows (vertical stack)\n",
        "Y = torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])          #torch.cat((X, Y), dim=1) → Concatenate along columns (horizontal stack)\n",
        "torch.cat((X,Y) , dim = 0 ) , torch.cat((X,Y) , dim = 1 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSXsZcJP3uLm",
        "outputId": "1cedd22d-2c34-498e-9c0a-4ac340b3d02b"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [ 2.,  1.,  4.,  3.],\n",
              "         [ 1.,  2.,  3.,  4.],\n",
              "         [ 4.,  3.,  2.,  1.]]),\n",
              " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
              "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X == Y  #compare"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zU14WGd6W0M",
        "outputId": "c5f05d3d-5829-4fc3-8238-52d268454ed5"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True, False,  True],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw59gyEE6csC",
        "outputId": "2ccf944e-3ef2-4485-84bd-6cc1fecd910b"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(66.)"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(3).reshape((3,1))\n",
        "b = torch.arange(2).reshape((1,2))\n",
        "a,b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lhZi5ka6zsJ",
        "outputId": "623371ae-08ac-40e9-aef4-8cc9ccdb6b40"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2]]),\n",
              " tensor([[0, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a+b  #Since a and b are 3 × 1 and 1 × 2 matrices, respectively, their shapes do not match up. Broadcasting produces a larger 3 × 2 matrix by replicating matrix a along the columns and matrix b along the rows beore adding them elementwise."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CB5h4A-7jsv",
        "outputId": "4e1f0d6c-bd72-4fd3-ca9e-cf2ae0f0b1f3"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before = id(Y)\n",
        "Y = Y + X\n",
        "id(Y) == before"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQYfU-ed7ufH",
        "outputId": "f0ca6451-d1f8-4f6c-c622-ee041d1f5546"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z = torch.zeros_like(Y)\n",
        "print('id(Z):', id(Z))\n",
        "Z[:] = X + Y\n",
        "print('id(Z):', id(Z))"
      ],
      "metadata": {
        "id": "xQmOi3QTnLE9",
        "outputId": "35c5c98e-b2b7-4524-ddff-a915a640281a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id(Z): 137647391929552\n",
            "id(Z): 137647391929552\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before = id(X)    # if the value of X is not reused in subsequent computations\n",
        "X += Y            # we can also use X[:] = X + Yor X += Y to reduce the memory overhead of the operation.\n",
        "id(X) == before"
      ],
      "metadata": {
        "id": "8ZV7ty81uELk",
        "outputId": "2efecbb3-a6b4-4234-8682-6d7b9a6a2c0b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = X.numpy()\n",
        "B = torch.from_numpy(A)\n",
        "type(A), type(B)"
      ],
      "metadata": {
        "id": "zv1JXwauuutl",
        "outputId": "252d37e6-0906-4bbc-a3b2-f176ede04ab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct version using scalar tensor (no square brackets)\n",
        "a = torch.tensor(3.5)  # Now `a` is a scalar tensor\n",
        "\n",
        "print(a)         # tensor(3.5)\n",
        "print(a.item())  # Returns 3.5 as Python float\n",
        "print(float(a))  # Converts to float: 3.5\n",
        "print(int(a))    # Converts to int: 3"
      ],
      "metadata": {
        "id": "a5qRDYYru9Ch",
        "outputId": "6ecd301d-f796-4986-8874-4895098da902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.5000)\n",
            "3.5\n",
            "3.5\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # Import the os module to interact with the file system\n",
        "\n",
        "# Create a directory '../data' if it doesn't already exist\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "\n",
        "# Define the path to the CSV file\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "\n",
        "# Open the file in write mode and write the CSV content\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('''NumRooms,RoofType,Price\n",
        "NA,NA,127500\n",
        "2,NA,106000\n",
        "4,Slate,178100\n",
        "NA,NA,140000''')"
      ],
      "metadata": {
        "id": "SPrrMLWIvZdf"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "0Q-HktGsvxKn",
        "outputId": "abcb88a4-7c15-4c38-f187-3e7b9222c62e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms RoofType   Price\n",
            "0       NaN      NaN  127500\n",
            "1       2.0      NaN  106000\n",
            "2       4.0    Slate  178100\n",
            "3       NaN      NaN  140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into input features and target values\n",
        "\n",
        "# Select the first two columns (NumRooms and RoofType) as input features\n",
        "inputs = data.iloc[:, 0:2]\n",
        "\n",
        "# Select the third column (Price) as the target variable\n",
        "targets = data.iloc[:, 2]\n",
        "\n",
        "# Convert categorical columns in 'inputs' into one-hot encoded format\n",
        "# 'dummy_na=True' means it will also create an extra column for missing values (NaNs)\n",
        "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "\n",
        "# Print the one-hot encoded input features\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "hbX-AZe6wXOF",
        "outputId": "4f862942-d760-4dea-a7c0-9a549d0f929f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  RoofType_Slate  RoofType_nan\n",
            "0       NaN           False          True\n",
            "1       2.0           False          True\n",
            "2       4.0            True         False\n",
            "3       NaN           False          True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.fillna(inputs.mean()) #For missing numerical values, one common heuristic is to replace the NaN entries with the mean value of the corresponding column.\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "eYQybeNIwfaq",
        "outputId": "faf199ef-00ba-4937-a5ed-baea3c8a5dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  RoofType_Slate  RoofType_nan\n",
            "0       3.0           False          True\n",
            "1       2.0           False          True\n",
            "2       4.0            True         False\n",
            "3       3.0           False          True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # Import PyTorch\n",
        "\n",
        "# Convert the one-hot encoded input DataFrame `inputs` into a NumPy array of type float,\n",
        "# then wrap it into a PyTorch tensor. This will be the input feature tensor.\n",
        "X = torch.tensor(inputs.to_numpy(dtype=float))\n",
        "\n",
        "# Convert the target Series `targets` (Price column) into a NumPy array of type float,\n",
        "# then wrap it into a PyTorch tensor. This will be the output (label) tensor.\n",
        "y = torch.tensor(targets.to_numpy(dtype=float))\n",
        "\n",
        "# Return both tensors (X for inputs, y for labels)\n",
        "X, y"
      ],
      "metadata": {
        "id": "GXY7QS8PwlWV",
        "outputId": "aac3dfae-63af-4999-d1e7-f2868252eadf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3., 0., 1.],\n",
              "         [2., 0., 1.],\n",
              "         [4., 1., 0.],\n",
              "         [3., 0., 1.]], dtype=torch.float64),\n",
              " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0)\n",
        "y = torch.tensor(2.0)\n",
        "x + y, x * y, x / y, x**y"
      ],
      "metadata": {
        "id": "FXiy9_-ZxwM1",
        "outputId": "276b23b5-7d0c-4f44-b7e6-fea1a41c8647",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VECTOR"
      ],
      "metadata": {
        "id": "R5I9KJFQyFxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3)\n",
        "x"
      ],
      "metadata": {
        "id": "FHu3I3blyLyu",
        "outputId": "585548ff-88d8-4e1f-a6ae-48ab439896ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[2]"
      ],
      "metadata": {
        "id": "JfD7V9LRyfgm",
        "outputId": "af411e30-30f8-403e-dcb6-f11e70c502ae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "id": "taNHxbZ9ymOe",
        "outputId": "d9fb05cd-d3e3-43ca-8a7a-a4e6df2cd057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "-piYREq-yoPw",
        "outputId": "66db8e7f-ece5-4c82-d697-3278f5dcb255",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MATRICES"
      ],
      "metadata": {
        "id": "mwteQyiqyx2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(6).reshape(3, 2)\n",
        "A"
      ],
      "metadata": {
        "id": "iZ_uSq7ey4BH",
        "outputId": "30aa4873-47f0-4378-d606-0740cf05a9b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.T  #to transpose a matrix"
      ],
      "metadata": {
        "id": "nIVAcBEBy-5e",
        "outputId": "329fff87-9db0-42dd-c6db-6e588cba5f74",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 2, 4],\n",
              "        [1, 3, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
        "A == A.T   #Symmetric matrices are the subset of square matrices that are equal to their own transposes: A = A (transpose)."
      ],
      "metadata": {
        "id": "l4PScz3EzaN1",
        "outputId": "d55904c9-831f-4f3d-be0f-ad1b384a225c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(24).reshape(2, 3, 4)"
      ],
      "metadata": {
        "id": "glipZGG7zp1M",
        "outputId": "7a0ed719-90fb-4a19-b278-ffa6eb5d8628",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
        "B = A.clone() # Assign a copy of A to B by allocating new memory\n",
        "A, A + B"
      ],
      "metadata": {
        "id": "no12hcxuz05l",
        "outputId": "014f5644-3d17-4f51-f128-795aabf8d7b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 1., 2.],\n",
              "         [3., 4., 5.]]),\n",
              " tensor([[ 0.,  2.,  4.],\n",
              "         [ 6.,  8., 10.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A * B  #Hadamard Product"
      ],
      "metadata": {
        "id": "ktlHnxKn0B5V",
        "outputId": "ccf44fa8-6b7c-4847-8f6f-a1017fe05a32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  4.],\n",
              "        [ 9., 16., 25.]])"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = 2  # 'a' is a scalar (integer)\n",
        "\n",
        "# Create a tensor with values from 0 to 23 and reshape it into shape (2, 3, 4)\n",
        "X = torch.arange(24).reshape(2, 3, 4)\n",
        "# Add scalar 'a' to every element of tensor 'X' using broadcasting\n",
        "print(a + X)\n",
        "# Multiply scalar 'a' with every element of tensor 'X' and get the shape of the result\n",
        "print((a * X).shape)"
      ],
      "metadata": {
        "id": "da-5DFGN1UQ9",
        "outputId": "7276190c-8831-4108-c896-5f26adaf3664",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 2,  3,  4,  5],\n",
            "         [ 6,  7,  8,  9],\n",
            "         [10, 11, 12, 13]],\n",
            "\n",
            "        [[14, 15, 16, 17],\n",
            "         [18, 19, 20, 21],\n",
            "         [22, 23, 24, 25]]])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3, dtype=torch.float32)\n",
        "x, x.sum()"
      ],
      "metadata": {
        "id": "wK4ku3cK2Hga",
        "outputId": "a37e336a-e661-4618-8222-d6a91c5f16d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2.]), tensor(3.))"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape, A.sum()"
      ],
      "metadata": {
        "id": "CQ0OBszZ2Ohy",
        "outputId": "9a46a2c6-bb29-4488-872a-cb627c1bd61e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), tensor(15.))"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape, A.sum(axis=0).shape  # Sum the elements of tensor 'A' along axis 0 (the first dimension)\n",
        "# This collapses axis 0 by adding together elements at the same position in that dimension,\n",
        "# resulting in a tensor with one fewer dimension along axis 0"
      ],
      "metadata": {
        "id": "40i1HcAu2T2R",
        "outputId": "46c693d2-e42e-4df1-e3b0-050eebc2d1ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape, A.sum(axis=1).shape"
      ],
      "metadata": {
        "id": "2jXjOVth2d-w",
        "outputId": "f7422af3-ee4e-4c09-8c08-771894157ad8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([2]))"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.sum(axis=[0, 1]) == A.sum() # Same as A.sum()"
      ],
      "metadata": {
        "id": "Iu9Z-UQ44nrZ",
        "outputId": "b4aebb9c-1380-40c7-a461-c14e8e182831",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.mean(), A.sum() / A.numel()"
      ],
      "metadata": {
        "id": "b5fiQnXs4zsQ",
        "outputId": "2b867854-56ca-4b85-bf7f-4c949500c612",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.5000), tensor(2.5000))"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
      ],
      "metadata": {
        "id": "opm1mhP_45iX",
        "outputId": "34a7f2d9-30af-4fa3-dae4-2236c7aaa219",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.5000, 2.5000, 3.5000]), tensor([1.5000, 2.5000, 3.5000]))"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum the elements of tensor 'A' along axis 1 (the second dimension)\n",
        "# keepdims=True keeps the reduced dimension as size 1, so the output tensor\n",
        "# retains the same number of dimensions as 'A'\n",
        "sum_A = A.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Return the summed tensor and its shape\n",
        "sum_A, sum_A.shape\n"
      ],
      "metadata": {
        "id": "Ez-8ikiI5GmW",
        "outputId": "0b6b386d-2ba1-4969-84eb-303ba1cf83f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 3.],\n",
              "         [12.]]),\n",
              " torch.Size([2, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A / sum_A"
      ],
      "metadata": {
        "id": "tG1mlYH_5xMD",
        "outputId": "44bbdc67-e675-41c7-8878-6cb75cf987d4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.3333, 0.6667],\n",
              "        [0.2500, 0.3333, 0.4167]])"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.cumsum(axis=0)"
      ],
      "metadata": {
        "id": "QZGXqow05_hr",
        "outputId": "8cabb4d3-fb47-4489-adff-6817e38f7dd3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [3., 5., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the cumulative sum of tensor 'A' along axis 0 (the first dimension)\n",
        "# This means for each element along axis 0, sum all previous elements up to the current one\n",
        "# The result has the same shape as 'A', but each element is the running total down the rows\n",
        "A.cumsum(axis=0)\n"
      ],
      "metadata": {
        "id": "XNqwDOPf6X1C",
        "outputId": "329392a0-49dc-4128-8335-c57037310e55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [3., 5., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.ones(3, dtype = torch.float32)  #Create a tensor 'y' of size 3, filled with ones, with data type float32\n",
        "x, y, torch.dot(x, y)"
      ],
      "metadata": {
        "id": "Zypuq4bf6Z-p",
        "outputId": "8bf31f18-0335-45f9-a6d8-75640c3c3106",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(x*y)   #Equivalently, we can calculate the dot product o two vectors by perorming an elementwise multiplication followed by a sum"
      ],
      "metadata": {
        "id": "brSTCBFV8GNz",
        "outputId": "947a6021-923a-49fb-da74-e6f8dd5b93ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A is a 2D tensor (matrix)\n",
        "# x is a 1D tensor (vector)\n",
        "\n",
        "# Get the shape of A (rows, columns)\n",
        "print(A.shape)\n",
        "\n",
        "# Get the shape of x (length of vector)\n",
        "print(x.shape)\n",
        "\n",
        "# Perform matrix-vector multiplication using torch.mv\n",
        "# Multiplies matrix A by vector x, producing a vector\n",
        "print(torch.mv(A, x))\n",
        "\n",
        "# Another way to do matrix-vector multiplication using @ operator\n",
        "# Equivalent to torch.mv(A, x)\n",
        "print(A @ x)"
      ],
      "metadata": {
        "id": "31IMQHvG9DkL",
        "outputId": "8c4e7eee-9c20-4c34-f808-06bd02288c66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([3])\n",
            "tensor([ 5., 14.])\n",
            "tensor([ 5., 14.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B = torch.ones(3, 4)\n",
        "torch.mm(A, B), A@B"
      ],
      "metadata": {
        "id": "GBe7lT2-9k8s",
        "outputId": "c55069f8-47d3-4b60-cd05-642cb7baa93b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 3.,  3.,  3.,  3.],\n",
              "         [12., 12., 12., 12.]]),\n",
              " tensor([[ 3.,  3.,  3.,  3.],\n",
              "         [12., 12., 12., 12.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Norms\n",
        "\n",
        "A **norm** is a function $\\|\\cdot\\|$ that maps a vector to a scalar and satisfies the following three properties:\n",
        "\n",
        "1. **Absolute scalability**: Given any vector $\\mathbf{x} \\in \\mathbb{R}^n$, if we scale it by a scalar $\\alpha \\in \\mathbb{R}$, its norm scales accordingly:\n",
        "   $$\\|\\alpha \\mathbf{x}\\| = |\\alpha| \\cdot \\|\\mathbf{x}\\|$$\n",
        "\n",
        "2. **Triangle inequality**: For any vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$:\n",
        "   $$\\|\\mathbf{x} + \\mathbf{y}\\| \\leq \\|\\mathbf{x}\\| + \\|\\mathbf{y}\\|$$\n",
        "\n",
        "3. **Positive definiteness**: For any vector $\\mathbf{x} \\in \\mathbb{R}^n$:\n",
        "   $$\\|\\mathbf{x}\\| \\geq 0 \\text{ with equality iff } \\mathbf{x} = \\mathbf{0}$$"
      ],
      "metadata": {
        "id": "gEKxRtT9AI_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ℓ₂ Norm (Euclidean Norm)\n",
        "\n",
        "Many functions are valid norms, and different norms encode different notions of size. The **Euclidean norm** (familiar from elementary geometry when calculating a right triangle's hypotenuse) is the square root of the sum of squares of a vector's elements.\n",
        "\n",
        "Formally, this is called the $\\ell_{2}$-norm and is expressed as:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{x}\\|_{2} = \\sqrt{\\sum_{i=1}^{n} x_{i}^{2}}\n",
        "$$\n",
        "\n",
        "Key properties:\n",
        "- Generalizes the notion of \"length\" to $n$-dimensional spaces\n",
        "- Invariant under rotations (important for many machine learning applications)\n",
        "- Computed via the `norm()` method in most linear algebra libraries\n"
      ],
      "metadata": {
        "id": "5SrWNiQbAtN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = torch.tensor([3.0, -4.0])\n",
        "torch.norm(u)"
      ],
      "metadata": {
        "id": "DgQp2tpxAsoN",
        "outputId": "d89f5fff-602e-4b70-e137-acbf86e73373",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ℓ₁ Norm (Manhattan Norm)\n",
        "\n",
        "The **ℓ₁ norm** (also known as the *Manhattan distance* or *Taxicab norm*) sums the absolute values of a vector's elements:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{x}\\|_{1} = \\sum_{i=1}^{n} |x_{i}|\n",
        "$$\n",
        "\n",
        "### Key Characteristics:\n",
        "- **Robustness**: Less sensitive to outliers compared to the ℓ₂ norm\n",
        "- **Geometry**: Corresponds to the distance traveled along grid lines (like Manhattan's street grid)\n",
        "- **Computation**: Implemented by composing absolute value with summation\n",
        "\n",
        "### Comparison with ℓ₂ Norm:\n",
        "| Feature        | ℓ₁ Norm                     | ℓ₂ Norm                     |\n",
        "|----------------|----------------------------|----------------------------|\n",
        "| Outlier Sensitivity | Less sensitive         | More sensitive             |\n",
        "| Computation    | Sum of absolute values     | Square root of squared sums |\n",
        "| Sparsity       | Encourages sparse solutions | Produces smoother solutions |"
      ],
      "metadata": {
        "id": "K_pYOnNLBUJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.abs(u).sum()"
      ],
      "metadata": {
        "id": "mFTHWbJe_kMY",
        "outputId": "b803f9ad-677f-4057-8eb4-dc33bc913a4c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General ℓₚ Norms and Matrix Norms\n",
        "\n",
        "### ℓₚ Norms (Vector Norms)\n",
        "Both the ℓ₂ and ℓ₁ norms are special cases of the general **ℓₚ norms**:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{x}\\|_{p} = \\left(\\sum_{i=1}^{n}|x_{i}|^{p}\\right)^{1/p}\n",
        "$$\n",
        "\n",
        "**Special Cases:**\n",
        "- *p = 1*: Manhattan norm (ℓ₁)\n",
        "- *p = 2*: Euclidean norm (ℓ₂)\n",
        "- *p → ∞*: Maximum norm (ℓ∞)\n",
        "\n",
        "---\n",
        "\n",
        "### Matrix Norms\n",
        "For matrices, we consider two important norms:\n",
        "\n",
        "#### 1. Frobenius Norm\n",
        "The simplest matrix norm, which treats the matrix as a vector:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{X}\\|_{\\mathrm{F}} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}x_{ij}^{2}}\n",
        "$$\n",
        "\n",
        "**Properties:**\n",
        "- Analogous to the ℓ₂ norm for vectors\n",
        "- Easy to compute\n",
        "- Invariant under orthogonal transformations\n",
        "\n",
        "#### 2. Spectral Norm (mentioned)\n",
        "Measures the maximum scaling a matrix can apply to any vector:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{X}\\|_2 = \\max_{\\mathbf{v} \\neq 0} \\frac{\\|\\mathbf{X}\\mathbf{v}\\|_2}{\\|\\mathbf{v}\\|_2}\n",
        "$$\n",
        "\n",
        "**Key Point:**  \n",
        "The Frobenius norm is typically computed using `np.linalg.norm` in NumPy, while the spectral norm requires singular value decomposition."
      ],
      "metadata": {
        "id": "nbX1IDRQBsjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(torch.ones((4, 9)))"
      ],
      "metadata": {
        "id": "xswBUNmsCcDQ",
        "outputId": "b07f9872-345f-4c64-a567-20e9cc82049d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib_inline import backend_inline\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "tT2JQjyrDAjG",
        "outputId": "effcbb42-336b-47c8-9cab-641a9a9a15e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        }
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'd2l'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-493d2b204e6f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib_inline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend_inline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0md2l\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0md2l\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'd2l'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}