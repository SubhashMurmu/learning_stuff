{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMO9H8akoChThCdFIRPWaDt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SubhashMurmu/learning_stuff/blob/main/data_manipulation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install d2l==1.0.0a1.post0 --quiet\n",
        "\n",
        "\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "from matplotlib_inline import backend_inline\n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "wORIaNN5Dlxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Y8OQFXk1q6_4"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(12,dtype=torch.float32)   #to fill in the tensor x\n",
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tUYyY5SNrwfr",
        "outputId": "ce8f1d76-0f79-46d5-9df8-09d504f75b06"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11.])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.numel()  #no of elements in the tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP__6HZ0sVar",
        "outputId": "82a7ce39-31f1-4de3-de9c-583b22e61029"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape #to get dimension and size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ywFowljJssDC",
        "outputId": "f38963ca-8e13-483b-9670-c3c64b64ae09"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([12])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = x.reshape(3,4)  #(row , column)\n",
        "X                   #given a tensor of size n and target (h,w), we know that w=n/h.\n",
        "                    # if(soemthing , -1) then -1 denotes the above calculation done by the torch library"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BAzc15yJsxun",
        "outputId": "9875967a-dbb6-464a-c8ee-e60ff8132fe5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5.,  6.,  7.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.zeros((2,3,4)) #to make all zeroes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmepPwQjtX2S",
        "outputId": "a7998529-502b-4aec-e781-e255adbd5b58"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.],\n",
              "         [0., 0., 0., 0.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.ones((2,3,4)) #make all ones"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HSA8RGIxu8Tj",
        "outputId": "98dd12ba-d99c-4c4c-a7b4-b318b7d04dff"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]],\n",
              "\n",
              "        [[1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.],\n",
              "         [1., 1., 1., 1.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.randn(3,4) #random numbers from gaussian distribution"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Csp5tjeGvC28",
        "outputId": "1c560872-5656-46dd-e5ec-a9b938476f34"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1569, -1.3363, -0.5072, -0.2924],\n",
              "        [ 0.1408, -0.5381, -0.1850,  0.4016],\n",
              "        [ 2.2772,  0.1304,  0.5562,  0.6728]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])  #making my own custom tensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np3EiR-uvU5B",
        "outputId": "a4dede19-62e2-472c-b4ec-5587a8fb6697"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2, 1, 4, 3],\n",
              "        [1, 2, 3, 4],\n",
              "        [4, 3, 2, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[-1] , X[1:3] #slicing operation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WTBDsb0xXmZ",
        "outputId": "ba286232-2240-4aaf-c073-3956a8d01d83"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 8.,  9., 10., 11.]),\n",
              " tensor([[ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[1,2] = 17  #indexing\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUcAFEqfzSLf",
        "outputId": "85efeb7c-3e3a-40a4-ddb7-5adbc6016c2a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  2.,  3.],\n",
              "        [ 4.,  5., 17.,  7.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X[:2 , : ] = 12 #(row slicing, column slicing)\n",
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXgKYzbKzprM",
        "outputId": "01fb8499-79ee-4c1d-fcfd-342ff0487996"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[12., 12., 12., 12.],\n",
              "        [12., 12., 12., 12.],\n",
              "        [ 8.,  9., 10., 11.]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.exp(x)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BW1hfgc20Gv9",
        "outputId": "8e66c2de-3e8a-40be-972e-38e62832331b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([162754.7969, 162754.7969, 162754.7969, 162754.7969, 162754.7969,\n",
              "        162754.7969, 162754.7969, 162754.7969,   2980.9580,   8103.0840,\n",
              "         22026.4648,  59874.1406])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor([1,2,4,8])\n",
        "y = torch.tensor([2,2,2,2])\n",
        "x+y , x-y , x*y , x/y ,x**y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va5UaEAG2j_l",
        "outputId": "954ab2c3-37eb-4240-b4c6-264c212f4c47"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([ 3,  4,  6, 10]),\n",
              " tensor([-1,  0,  2,  6]),\n",
              " tensor([ 2,  4,  8, 16]),\n",
              " tensor([0.5000, 1.0000, 2.0000, 4.0000]),\n",
              " tensor([ 1,  4, 16, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.arange(12,dtype=torch.float32).reshape((3,4))    #torch.cat((X, Y), dim=0) → Concatenate along rows (vertical stack)\n",
        "Y = torch.tensor([[2,1,4,3],[1,2,3,4],[4,3,2,1]])          #torch.cat((X, Y), dim=1) → Concatenate along columns (horizontal stack)\n",
        "torch.cat((X,Y) , dim = 0 ) , torch.cat((X,Y) , dim = 1 )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSXsZcJP3uLm",
        "outputId": "87b5fd22-edb5-40d2-c2e6-16374c39b676"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0.,  1.,  2.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.],\n",
              "         [ 8.,  9., 10., 11.],\n",
              "         [ 2.,  1.,  4.,  3.],\n",
              "         [ 1.,  2.,  3.,  4.],\n",
              "         [ 4.,  3.,  2.,  1.]]),\n",
              " tensor([[ 0.,  1.,  2.,  3.,  2.,  1.,  4.,  3.],\n",
              "         [ 4.,  5.,  6.,  7.,  1.,  2.,  3.,  4.],\n",
              "         [ 8.,  9., 10., 11.,  4.,  3.,  2.,  1.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X == Y  #compare"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-zU14WGd6W0M",
        "outputId": "cd4495ef-91bf-436c-b2d2-ab6f9db64fa3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[False,  True, False,  True],\n",
              "        [False, False, False, False],\n",
              "        [False, False, False, False]])"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw59gyEE6csC",
        "outputId": "815d0fec-793b-4811-b267-f378475fe864"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(66.)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.arange(3).reshape((3,1))\n",
        "b = torch.arange(2).reshape((1,2))\n",
        "a,b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lhZi5ka6zsJ",
        "outputId": "4c5426e1-3f9b-4ddd-e462-e7e73db6403e"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0],\n",
              "         [1],\n",
              "         [2]]),\n",
              " tensor([[0, 1]]))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a+b  #Since a and b are 3 × 1 and 1 × 2 matrices, respectively, their shapes do not match up. Broadcasting produces a larger 3 × 2 matrix by replicating matrix a along the columns and matrix b along the rows beore adding them elementwise."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CB5h4A-7jsv",
        "outputId": "6a1d705c-2c5b-4061-adef-83defab05e0e"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [1, 2],\n",
              "        [2, 3]])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before = id(Y)\n",
        "Y = Y + X\n",
        "id(Y) == before"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQYfU-ed7ufH",
        "outputId": "f6d57850-bd93-4dc7-e063-76940e2e0101"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Z = torch.zeros_like(Y)\n",
        "print('id(Z):', id(Z))\n",
        "Z[:] = X + Y\n",
        "print('id(Z):', id(Z))"
      ],
      "metadata": {
        "id": "xQmOi3QTnLE9",
        "outputId": "fb991312-b9d3-463d-88b6-46ac4ae41e78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id(Z): 139099932363088\n",
            "id(Z): 139099932363088\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before = id(X)    # if the value of X is not reused in subsequent computations\n",
        "X += Y            # we can also use X[:] = X + Yor X += Y to reduce the memory overhead of the operation.\n",
        "id(X) == before"
      ],
      "metadata": {
        "id": "8ZV7ty81uELk",
        "outputId": "23be95cc-38cd-4375-f1e6-f1d33e82eeb2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = X.numpy()\n",
        "B = torch.from_numpy(A)\n",
        "type(A), type(B)"
      ],
      "metadata": {
        "id": "zv1JXwauuutl",
        "outputId": "9e562e04-34d7-401b-89c5-a7b26fc14a44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(numpy.ndarray, torch.Tensor)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Correct version using scalar tensor (no square brackets)\n",
        "a = torch.tensor(3.5)  # Now `a` is a scalar tensor\n",
        "\n",
        "print(a)         # tensor(3.5)\n",
        "print(a.item())  # Returns 3.5 as Python float\n",
        "print(float(a))  # Converts to float: 3.5\n",
        "print(int(a))    # Converts to int: 3"
      ],
      "metadata": {
        "id": "a5qRDYYru9Ch",
        "outputId": "28d104e9-985f-49c1-dfbb-4dff3f102495",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(3.5000)\n",
            "3.5\n",
            "3.5\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os  # Import the os module to interact with the file system\n",
        "\n",
        "# Create a directory '../data' if it doesn't already exist\n",
        "os.makedirs(os.path.join('..', 'data'), exist_ok=True)\n",
        "\n",
        "# Define the path to the CSV file\n",
        "data_file = os.path.join('..', 'data', 'house_tiny.csv')\n",
        "\n",
        "# Open the file in write mode and write the CSV content\n",
        "with open(data_file, 'w') as f:\n",
        "    f.write('''NumRooms,RoofType,Price\n",
        "NA,NA,127500\n",
        "2,NA,106000\n",
        "4,Slate,178100\n",
        "NA,NA,140000''')"
      ],
      "metadata": {
        "id": "SPrrMLWIvZdf"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(data_file)\n",
        "print(data)"
      ],
      "metadata": {
        "id": "0Q-HktGsvxKn",
        "outputId": "dbc4a1f1-acef-45d8-d9e9-0e26e61e45e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms RoofType   Price\n",
            "0       NaN      NaN  127500\n",
            "1       2.0      NaN  106000\n",
            "2       4.0    Slate  178100\n",
            "3       NaN      NaN  140000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into input features and target values\n",
        "\n",
        "# Select the first two columns (NumRooms and RoofType) as input features\n",
        "inputs = data.iloc[:, 0:2]\n",
        "\n",
        "# Select the third column (Price) as the target variable\n",
        "targets = data.iloc[:, 2]\n",
        "\n",
        "# Convert categorical columns in 'inputs' into one-hot encoded format\n",
        "# 'dummy_na=True' means it will also create an extra column for missing values (NaNs)\n",
        "inputs = pd.get_dummies(inputs, dummy_na=True)\n",
        "\n",
        "# Print the one-hot encoded input features\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "hbX-AZe6wXOF",
        "outputId": "96cfaaec-76a6-470d-aa36-21368be5208f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  RoofType_Slate  RoofType_nan\n",
            "0       NaN           False          True\n",
            "1       2.0           False          True\n",
            "2       4.0            True         False\n",
            "3       NaN           False          True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = inputs.fillna(inputs.mean()) #For missing numerical values, one common heuristic is to replace the NaN entries with the mean value of the corresponding column.\n",
        "print(inputs)"
      ],
      "metadata": {
        "id": "eYQybeNIwfaq",
        "outputId": "ee5365ff-8bb4-47ed-b393-34a5613cd430",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   NumRooms  RoofType_Slate  RoofType_nan\n",
            "0       3.0           False          True\n",
            "1       2.0           False          True\n",
            "2       4.0            True         False\n",
            "3       3.0           False          True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  # Import PyTorch\n",
        "\n",
        "# Convert the one-hot encoded input DataFrame `inputs` into a NumPy array of type float,\n",
        "# then wrap it into a PyTorch tensor. This will be the input feature tensor.\n",
        "X = torch.tensor(inputs.to_numpy(dtype=float))\n",
        "\n",
        "# Convert the target Series `targets` (Price column) into a NumPy array of type float,\n",
        "# then wrap it into a PyTorch tensor. This will be the output (label) tensor.\n",
        "y = torch.tensor(targets.to_numpy(dtype=float))\n",
        "\n",
        "# Return both tensors (X for inputs, y for labels)\n",
        "X, y"
      ],
      "metadata": {
        "id": "GXY7QS8PwlWV",
        "outputId": "a31cb650-04e0-4141-cc58-3c159f50de8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[3., 0., 1.],\n",
              "         [2., 0., 1.],\n",
              "         [4., 1., 0.],\n",
              "         [3., 0., 1.]], dtype=torch.float64),\n",
              " tensor([127500., 106000., 178100., 140000.], dtype=torch.float64))"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.tensor(3.0)\n",
        "y = torch.tensor(2.0)\n",
        "x + y, x * y, x / y, x**y"
      ],
      "metadata": {
        "id": "FXiy9_-ZxwM1",
        "outputId": "6fb14a95-8b66-4858-b186-7468833e3507",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(5.), tensor(6.), tensor(1.5000), tensor(9.))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VECTOR"
      ],
      "metadata": {
        "id": "R5I9KJFQyFxm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3)\n",
        "x"
      ],
      "metadata": {
        "id": "FHu3I3blyLyu",
        "outputId": "92c184cd-98d4-436f-bf2e-c93d26228ca0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 1, 2])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x[2]"
      ],
      "metadata": {
        "id": "JfD7V9LRyfgm",
        "outputId": "26dce423-f7b0-4d55-e1e4-40e18a88ead9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(x)"
      ],
      "metadata": {
        "id": "taNHxbZ9ymOe",
        "outputId": "e6544658-e2f5-4bbc-9ba7-359282f4c47f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "id": "-piYREq-yoPw",
        "outputId": "847c884c-fb12-4685-edea-ed4c326022c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MATRICES"
      ],
      "metadata": {
        "id": "mwteQyiqyx2O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(6).reshape(3, 2)\n",
        "A"
      ],
      "metadata": {
        "id": "iZ_uSq7ey4BH",
        "outputId": "9fea0118-5fe1-4671-9ac9-2b657564a038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1],\n",
              "        [2, 3],\n",
              "        [4, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.T  #to transpose a matrix"
      ],
      "metadata": {
        "id": "nIVAcBEBy-5e",
        "outputId": "f4e20e90-6b46-446a-d945-186d5bf7dd75",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 2, 4],\n",
              "        [1, 3, 5]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.tensor([[1, 2, 3], [2, 0, 4], [3, 4, 5]])\n",
        "A == A.T   #Symmetric matrices are the subset of square matrices that are equal to their own transposes: A = A (transpose)."
      ],
      "metadata": {
        "id": "l4PScz3EzaN1",
        "outputId": "16f58f81-5076-4822-a5d4-e68f59b11bbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[True, True, True],\n",
              "        [True, True, True],\n",
              "        [True, True, True]])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.arange(24).reshape(2, 3, 4)"
      ],
      "metadata": {
        "id": "glipZGG7zp1M",
        "outputId": "4a3cdf05-ae10-4f8c-a913-dd53530f797b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 0,  1,  2,  3],\n",
              "         [ 4,  5,  6,  7],\n",
              "         [ 8,  9, 10, 11]],\n",
              "\n",
              "        [[12, 13, 14, 15],\n",
              "         [16, 17, 18, 19],\n",
              "         [20, 21, 22, 23]]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A = torch.arange(6, dtype=torch.float32).reshape(2, 3)\n",
        "B = A.clone() # Assign a copy of A to B by allocating new memory\n",
        "A, A + B"
      ],
      "metadata": {
        "id": "no12hcxuz05l",
        "outputId": "40ccdf2b-0598-4e16-d92d-9fc0dd822490",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0., 1., 2.],\n",
              "         [3., 4., 5.]]),\n",
              " tensor([[ 0.,  2.,  4.],\n",
              "         [ 6.,  8., 10.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A * B  #Hadamard Product"
      ],
      "metadata": {
        "id": "ktlHnxKn0B5V",
        "outputId": "bbfce136-2876-4835-f717-753f65aec1ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.,  1.,  4.],\n",
              "        [ 9., 16., 25.]])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "a = 2  # 'a' is a scalar (integer)\n",
        "\n",
        "# Create a tensor with values from 0 to 23 and reshape it into shape (2, 3, 4)\n",
        "X = torch.arange(24).reshape(2, 3, 4)\n",
        "# Add scalar 'a' to every element of tensor 'X' using broadcasting\n",
        "print(a + X)\n",
        "# Multiply scalar 'a' with every element of tensor 'X' and get the shape of the result\n",
        "print((a * X).shape)"
      ],
      "metadata": {
        "id": "da-5DFGN1UQ9",
        "outputId": "7446415d-f1ca-4434-ac49-170732a19e01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 2,  3,  4,  5],\n",
            "         [ 6,  7,  8,  9],\n",
            "         [10, 11, 12, 13]],\n",
            "\n",
            "        [[14, 15, 16, 17],\n",
            "         [18, 19, 20, 21],\n",
            "         [22, 23, 24, 25]]])\n",
            "torch.Size([2, 3, 4])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.arange(3, dtype=torch.float32)\n",
        "x, x.sum()"
      ],
      "metadata": {
        "id": "wK4ku3cK2Hga",
        "outputId": "950e6b81-6b98-4851-af19-24ba1d4358ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2.]), tensor(3.))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape, A.sum()"
      ],
      "metadata": {
        "id": "CQ0OBszZ2Ohy",
        "outputId": "afcf6095-bd71-4789-bc9c-cc5aaed26fa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), tensor(15.))"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape, A.sum(axis=0).shape  # Sum the elements of tensor 'A' along axis 0 (the first dimension)\n",
        "# This collapses axis 0 by adding together elements at the same position in that dimension,\n",
        "# resulting in a tensor with one fewer dimension along axis 0"
      ],
      "metadata": {
        "id": "40i1HcAu2T2R",
        "outputId": "a44a7f1e-2b49-4ba1-8c72-ff9df0f90355",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([3]))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.shape, A.sum(axis=1).shape"
      ],
      "metadata": {
        "id": "2jXjOVth2d-w",
        "outputId": "0d9649e9-07e3-401f-f91a-7d037760cf7a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 3]), torch.Size([2]))"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.sum(axis=[0, 1]) == A.sum() # Same as A.sum()"
      ],
      "metadata": {
        "id": "Iu9Z-UQ44nrZ",
        "outputId": "5c3b5235-f23d-4d5e-e2d6-0114b5f2e901",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(True)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.mean(), A.sum() / A.numel()"
      ],
      "metadata": {
        "id": "b5fiQnXs4zsQ",
        "outputId": "fff9d00e-ee4a-4309-a8c1-30afdff6c1c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(2.5000), tensor(2.5000))"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.mean(axis=0), A.sum(axis=0) / A.shape[0]"
      ],
      "metadata": {
        "id": "opm1mhP_45iX",
        "outputId": "ac35d564-183e-4f6e-cacd-6af65bdc4170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.5000, 2.5000, 3.5000]), tensor([1.5000, 2.5000, 3.5000]))"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sum the elements of tensor 'A' along axis 1 (the second dimension)\n",
        "# keepdims=True keeps the reduced dimension as size 1, so the output tensor\n",
        "# retains the same number of dimensions as 'A'\n",
        "sum_A = A.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Return the summed tensor and its shape\n",
        "sum_A, sum_A.shape\n"
      ],
      "metadata": {
        "id": "Ez-8ikiI5GmW",
        "outputId": "791f92b2-2496-4890-a29a-f5bebf9ed9ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 3.],\n",
              "         [12.]]),\n",
              " torch.Size([2, 1]))"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A / sum_A"
      ],
      "metadata": {
        "id": "tG1mlYH_5xMD",
        "outputId": "feb53343-b708-4eb5-ffcb-ccc6c7124b32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0000, 0.3333, 0.6667],\n",
              "        [0.2500, 0.3333, 0.4167]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "A.cumsum(axis=0)"
      ],
      "metadata": {
        "id": "QZGXqow05_hr",
        "outputId": "46d2969d-4357-4b5b-ed2b-bf84967d819d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [3., 5., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the cumulative sum of tensor 'A' along axis 0 (the first dimension)\n",
        "# This means for each element along axis 0, sum all previous elements up to the current one\n",
        "# The result has the same shape as 'A', but each element is the running total down the rows\n",
        "A.cumsum(axis=0)\n"
      ],
      "metadata": {
        "id": "XNqwDOPf6X1C",
        "outputId": "06be9e8f-ac4e-4bae-d3bc-2964046a9047",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1., 2.],\n",
              "        [3., 5., 7.]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.ones(3, dtype = torch.float32)  #Create a tensor 'y' of size 3, filled with ones, with data type float32\n",
        "x, y, torch.dot(x, y)"
      ],
      "metadata": {
        "id": "Zypuq4bf6Z-p",
        "outputId": "2c5d85a5-0eac-47f2-98a3-448ad648bea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2.]), tensor([1., 1., 1.]), tensor(3.))"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.sum(x*y)   #Equivalently, we can calculate the dot product o two vectors by perorming an elementwise multiplication followed by a sum"
      ],
      "metadata": {
        "id": "brSTCBFV8GNz",
        "outputId": "9787c7ec-a3f4-40a3-e65c-cc8aadc97d48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(3.)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A is a 2D tensor (matrix)\n",
        "# x is a 1D tensor (vector)\n",
        "\n",
        "# Get the shape of A (rows, columns)\n",
        "print(A.shape)\n",
        "\n",
        "# Get the shape of x (length of vector)\n",
        "print(x.shape)\n",
        "\n",
        "# Perform matrix-vector multiplication using torch.mv\n",
        "# Multiplies matrix A by vector x, producing a vector\n",
        "print(torch.mv(A, x))\n",
        "\n",
        "# Another way to do matrix-vector multiplication using @ operator\n",
        "# Equivalent to torch.mv(A, x)\n",
        "print(A @ x)"
      ],
      "metadata": {
        "id": "31IMQHvG9DkL",
        "outputId": "acf84448-39e7-4707-ca14-37681f92965f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 3])\n",
            "torch.Size([3])\n",
            "tensor([ 5., 14.])\n",
            "tensor([ 5., 14.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "B = torch.ones(3, 4)\n",
        "torch.mm(A, B), A@B"
      ],
      "metadata": {
        "id": "GBe7lT2-9k8s",
        "outputId": "0b0322a7-2db2-4373-d18e-bea2578002a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 3.,  3.,  3.,  3.],\n",
              "         [12., 12., 12., 12.]]),\n",
              " tensor([[ 3.,  3.,  3.,  3.],\n",
              "         [12., 12., 12., 12.]]))"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Norms\n",
        "\n",
        "A **norm** is a function $\\|\\cdot\\|$ that maps a vector to a scalar and satisfies the following three properties:\n",
        "\n",
        "1. **Absolute scalability**: Given any vector $\\mathbf{x} \\in \\mathbb{R}^n$, if we scale it by a scalar $\\alpha \\in \\mathbb{R}$, its norm scales accordingly:\n",
        "   $$\\|\\alpha \\mathbf{x}\\| = |\\alpha| \\cdot \\|\\mathbf{x}\\|$$\n",
        "\n",
        "2. **Triangle inequality**: For any vectors $\\mathbf{x}, \\mathbf{y} \\in \\mathbb{R}^n$:\n",
        "   $$\\|\\mathbf{x} + \\mathbf{y}\\| \\leq \\|\\mathbf{x}\\| + \\|\\mathbf{y}\\|$$\n",
        "\n",
        "3. **Positive definiteness**: For any vector $\\mathbf{x} \\in \\mathbb{R}^n$:\n",
        "   $$\\|\\mathbf{x}\\| \\geq 0 \\text{ with equality iff } \\mathbf{x} = \\mathbf{0}$$"
      ],
      "metadata": {
        "id": "gEKxRtT9AI_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ℓ₂ Norm (Euclidean Norm)\n",
        "\n",
        "Many functions are valid norms, and different norms encode different notions of size. The **Euclidean norm** (familiar from elementary geometry when calculating a right triangle's hypotenuse) is the square root of the sum of squares of a vector's elements.\n",
        "\n",
        "Formally, this is called the $\\ell_{2}$-norm and is expressed as:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{x}\\|_{2} = \\sqrt{\\sum_{i=1}^{n} x_{i}^{2}}\n",
        "$$\n",
        "\n",
        "Key properties:\n",
        "- Generalizes the notion of \"length\" to $n$-dimensional spaces\n",
        "- Invariant under rotations (important for many machine learning applications)\n",
        "- Computed via the `norm()` method in most linear algebra libraries\n"
      ],
      "metadata": {
        "id": "5SrWNiQbAtN-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "u = torch.tensor([3.0, -4.0])\n",
        "torch.norm(u)"
      ],
      "metadata": {
        "id": "DgQp2tpxAsoN",
        "outputId": "400fdff4-b9fd-4267-a4e1-f79a820fdddc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(5.)"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ℓ₁ Norm (Manhattan Norm)\n",
        "\n",
        "The **ℓ₁ norm** (also known as the *Manhattan distance* or *Taxicab norm*) sums the absolute values of a vector's elements:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{x}\\|_{1} = \\sum_{i=1}^{n} |x_{i}|\n",
        "$$\n",
        "\n",
        "### Key Characteristics:\n",
        "- **Robustness**: Less sensitive to outliers compared to the ℓ₂ norm\n",
        "- **Geometry**: Corresponds to the distance traveled along grid lines (like Manhattan's street grid)\n",
        "- **Computation**: Implemented by composing absolute value with summation\n",
        "\n",
        "### Comparison with ℓ₂ Norm:\n",
        "| Feature        | ℓ₁ Norm                     | ℓ₂ Norm                     |\n",
        "|----------------|----------------------------|----------------------------|\n",
        "| Outlier Sensitivity | Less sensitive         | More sensitive             |\n",
        "| Computation    | Sum of absolute values     | Square root of squared sums |\n",
        "| Sparsity       | Encourages sparse solutions | Produces smoother solutions |"
      ],
      "metadata": {
        "id": "K_pYOnNLBUJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.abs(u).sum()"
      ],
      "metadata": {
        "id": "mFTHWbJe_kMY",
        "outputId": "079eefcf-8b11-4919-d5cf-13c3ad4e6751",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(7.)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## General ℓₚ Norms and Matrix Norms\n",
        "\n",
        "### ℓₚ Norms (Vector Norms)\n",
        "Both the ℓ₂ and ℓ₁ norms are special cases of the general **ℓₚ norms**:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{x}\\|_{p} = \\left(\\sum_{i=1}^{n}|x_{i}|^{p}\\right)^{1/p}\n",
        "$$\n",
        "\n",
        "**Special Cases:**\n",
        "- *p = 1*: Manhattan norm (ℓ₁)\n",
        "- *p = 2*: Euclidean norm (ℓ₂)\n",
        "- *p → ∞*: Maximum norm (ℓ∞)\n",
        "\n",
        "---\n",
        "\n",
        "### Matrix Norms\n",
        "For matrices, we consider two important norms:\n",
        "\n",
        "#### 1. Frobenius Norm\n",
        "The simplest matrix norm, which treats the matrix as a vector:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{X}\\|_{\\mathrm{F}} = \\sqrt{\\sum_{i=1}^{m}\\sum_{j=1}^{n}x_{ij}^{2}}\n",
        "$$\n",
        "\n",
        "**Properties:**\n",
        "- Analogous to the ℓ₂ norm for vectors\n",
        "- Easy to compute\n",
        "- Invariant under orthogonal transformations\n",
        "\n",
        "#### 2. Spectral Norm (mentioned)\n",
        "Measures the maximum scaling a matrix can apply to any vector:\n",
        "\n",
        "$$\n",
        "\\|\\mathbf{X}\\|_2 = \\max_{\\mathbf{v} \\neq 0} \\frac{\\|\\mathbf{X}\\mathbf{v}\\|_2}{\\|\\mathbf{v}\\|_2}\n",
        "$$\n",
        "\n",
        "**Key Point:**  \n",
        "The Frobenius norm is typically computed using `np.linalg.norm` in NumPy, while the spectral norm requires singular value decomposition."
      ],
      "metadata": {
        "id": "nbX1IDRQBsjI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.norm(torch.ones((4, 9)))"
      ],
      "metadata": {
        "id": "xswBUNmsCcDQ",
        "outputId": "a0eb4a4f-0666-46ea-d0e2-6fd9aa3be7ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(6.)"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "R3f7p-k6Onol"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Derivatives and Differentiation\n",
        "\n",
        "### Fundamental Concept\n",
        "A **derivative** measures how a function changes as its inputs change infinitesimally. In machine learning, derivatives tell us how adjusting parameters affects the loss function.\n",
        "\n",
        "### Formal Definition\n",
        "For a scalar function $f: \\mathbb{R} \\to \\mathbb{R}$, the derivative at point $x$ is:\n",
        "\n",
        "$$\n",
        "f'(x) = \\lim_{h \\to 0} \\frac{f(x+h) - f(x)}{h}\n",
        "$$\n",
        "\n",
        "**Key Components:**\n",
        "- $h$: Infinitesimal perturbation\n",
        "- Numerator: Change in function value\n",
        "- Limit: Behavior as $h$ approaches zero\n",
        "\n",
        "### Differentiability\n",
        "- A function is **differentiable at x** if $f'(x)$ exists\n",
        "- **Differentiable on a set** if derivatives exist for all points in that set\n",
        "- **Important Note**: Not all useful functions (e.g., accuracy, AUC) are differentiable\n",
        "\n",
        "### Practical Implications\n",
        "- Deep learning relies on differentiable surrogate functions\n",
        "- Derivatives enable optimization via gradient descent\n",
        "\n",
        "### Example: Quadratic Function\n",
        "Consider $u = f(x) = 3x^2 - 4x$:\n",
        "\n",
        "```python\n",
        "def f(x):\n",
        "    return 3*x**2 - 4*x\n",
        "\n",
        "# Derivative (computed manually)\n",
        "def df(x):\n",
        "    return 6*x - 4"
      ],
      "metadata": {
        "id": "4fp57MvKPkUU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f(x):\n",
        "  return 3 * x ** 2 - 4 * x"
      ],
      "metadata": {
        "id": "tT2JQjyrDAjG"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loop over step sizes h = 10^-1 to 10^-5\n",
        "for h in 10.0**np.arange(-1, -6, -1):\n",
        "    # Compute the finite difference approximation of the derivative at x = 1\n",
        "    # and print h and the result, both formatted to 5 decimal places\n",
        "    print(f'h={h:.5f}, numerical limit={(f(1+h)-f(1))/h:.5f}')\n"
      ],
      "metadata": {
        "id": "7UCyUmikP0fN",
        "outputId": "96353c70-ff14-499d-e089-34c5b289cdb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "h=0.10000, numerical limit=2.30000\n",
            "h=0.01000, numerical limit=2.03000\n",
            "h=0.00100, numerical limit=2.00300\n",
            "h=0.00010, numerical limit=2.00030\n",
            "h=0.00001, numerical limit=2.00003\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Derivative Notations and Rules\n",
        "\n",
        "### Equivalent Notations\n",
        "For $y = f(x)$, these all represent the derivative:\n",
        "\n",
        "$$\n",
        "f'(x) = y' = \\frac{dy}{dx} = \\frac{df}{dx} = \\frac{d}{dx}f(x) = Df(x) = D_x f(x)\n",
        "$$\n",
        "\n",
        "Where $\\frac{d}{dx}$ and $D$ are **differentiation operators**.\n",
        "\n",
        "---\n",
        "\n",
        "### Common Derivatives\n",
        "| Function | Derivative |\n",
        "|----------|------------|\n",
        "| $C$ (constant) | $0$ |\n",
        "| $x^n$ | $nx^{n-1}$ |\n",
        "| $e^x$ | $e^x$ |\n",
        "| $\\ln x$ | $x^{-1}$ |\n",
        "\n",
        "---\n",
        "\n",
        "### Differentiation Rules\n",
        "For differentiable functions $f(x)$, $g(x)$ and constant $C$:\n",
        "\n",
        "1. **Constant Multiple Rule**:\n",
        "   $$\\frac{d}{dx}[Cf(x)] = C\\frac{d}{dx}f(x)$$\n",
        "\n",
        "2. **Sum Rule**:\n",
        "   $$\\frac{d}{dx}[f(x) + g(x)] = \\frac{d}{dx}f(x) + \\frac{d}{dx}g(x)$$\n",
        "\n",
        "3. **Product Rule**:\n",
        "   $$\\frac{d}{dx}[f(x)g(x)] = f(x)\\frac{d}{dx}g(x) + g(x)\\frac{d}{dx}f(x)$$\n",
        "\n",
        "4. **Quotient Rule**:\n",
        "   $$\\frac{d}{dx}\\left[\\frac{f(x)}{g(x)}\\right] = \\frac{g(x)\\frac{d}{dx}f(x) - f(x)\\frac{d}{dx}g(x)}{g^2(x)}$$\n",
        "\n",
        "---\n",
        "\n",
        "### Example Application\n",
        "For $f(x) = 3x^2 - 4x$:\n"
      ],
      "metadata": {
        "id": "wdvQc6TXRnnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib_inline import backend_inline  # Required for SVG output\n",
        "\n",
        "def use_svg_display():  #@save\n",
        "    \"\"\"Use the SVG format to display a plot in Jupyter or Colab.\"\"\"\n",
        "    backend_inline.set_matplotlib_formats('svg')\n"
      ],
      "metadata": {
        "id": "unA60dL7TatX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}